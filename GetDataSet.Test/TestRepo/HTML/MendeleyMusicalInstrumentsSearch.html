<!doctype html>
<html class="" lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- Google Tag Manager -->
	<script>
		(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T4NWPM8');
	</script>
	<!-- End Google Tag Manager -->

	<link rel="stylesheet" href="https://static.mendeley.com/weblet-data/build/2000490/css/main.css">
	<!--[if lt IE 9]>
    <script src="/js/lib/html5shiv/dist/html5shiv.min.js"></script>
  <![endif]-->
	<title>Mendeley Data</title>
	<meta name="description"
		content="Upload your research data, share with select users and make it publicly available and citable">

	<link rel="shortcut icon" href="/favicon.ico">

	<script>
		(function() {
    var supportsSVG = document.implementation.hasFeature("http://www.w3.org/TR/SVG11/feature#BasicStructure", "1.1");
    if (! supportsSVG) {
      document.documentElement.className += ' no-svg';
    }
    if (window.opener && window.name == 'authFlow') {
      window.opener.location.reload(true);
      window.close();
    }
  })();
	</script>

	<!-- NREUM: (1) -->

	<script
		src=///assets.adobedtm.com/376c5346e33126fdb6b2dbac81e307cbacfd7935/satelliteLib-4a7497b2b1d1900fe42ef2c13e32daeedf9c1642.js>
		</script> <!-- Optimizely AB Testing Tags -->
		<script type="text/javascript" async="" src=https://cdn.optimizely.com/js/238413261.js>
	</script>
	<!-- Optimizely AB Testing Tags -->

</head>

<body>



	<div>
		<header class="header">
			<a class="skip-to-content-link" href="#maincontent" data-component="skipToContentLink">Skip to main
				content</a>
			<div data-component="hamburgerNav" class="header-content-wrapper">
				<a class="header-main-logo" href="//www.mendeley.com" title="Mendeley"></a>

				<div class="header-content-wrapper-inner">
					<button type="button" class="header-nav-burger">
            <span class="header-nav-burger-bar"></span>
            <span class="header-nav-burger-bar"></span>
            <span class="header-nav-burger-bar"></span>
          </button>

					<div class="header-main header-content">
						<div class="header-main-contents">
							<a class="header-main-logo-menu" href="/">Mendeley Data</a>

							<div class="header-main-right">

								<a href="/login?redirectPath=/datasets"
									class="header-main-right-item header-main-right-item-burger-bottom">Sign in</a>
								<a href="/auth/register"
									class="header-main-right-item header-main-right-item-burger-bottom">Create
									account</a>
								<a href="//www.mendeley.com/downloads" class="header-download-btn">Download</a>
							</div>
						</div>
					</div>

					<div class="header-mdata header-content header-main-nav-part">
						<nav class="header-mdata-nav header-mdata-nav-loggedout-nav">
							<ul class="header-mdata-nav-list">
								<li class="header-mdata-nav-expandable">
									<a href="//www.mendeley.com/reference-management/reference-manager"
										class="header-mdata-nav-loggedout-nav-item header-mdata-nav-item-expands">Reference
										Management<span class="icon icon-chevron-down-accent"></span></a>
									<ul>
										<li><a href="//www.mendeley.com/reference-management/reference-manager">Reference
												Manager</a></li>
										<li><a href="//www.mendeley.com/reference-management/web-importer">Web
												Importer</a></li>
										<li><a href="//www.mendeley.com/reference-management/citation-plugin">Citation
												Plugin</a></li>
										<li><a href="//www.mendeley.com/reference-management/premium">Premium</a></li>
										<li><a href="//www.mendeley.com/reference-management/institutional-edition">Institutional
												Edition</a></li>
									</ul>
								</li>
								<li class="header-mdata-nav-expandable">
									<a href="//www.mendeley.com/research-network/community"
										class="header-mdata-nav-loggedout-nav-item header-mdata-nav-item-expands">Research
										Network<span class="icon icon-chevron-down-accent"></span></a>
									<ul>
										<li><a href="//www.mendeley.com/research-network/community">Community</a></li>
										<li><a href="//www.mendeley.com/research-network/groups">Groups</a></li>
										<li><a href="//www.mendeley.com/research-network/discover">Discover</a></li>
									</ul>
								</li>
								<li class="header-mdata-nav-expandable header-mdata-nav-expanded">
									<a href="/"
										class="header-mdata-nav-loggedout-nav-item header-mdata-nav-loggedout-nav-item-active header-mdata-nav-item-expands">Datasets<span class="icon icon-chevron-down-accent"></span></a>
									<ul>
										<li><a href="/datasets" class="active">Find Research Data</a></li>
										<li><a href="/drafts">My Datasets</a></li>
										<li><a href="/drafts/new">New Dataset</a></li>
										<li><a href="/faq">FAQ</a></li>
									</ul>
								</li>
								<li><a href="//www.mendeley.com/careers/"
										class="header-mdata-nav-loggedout-nav-item">Careers</a></li>
								<li><a href="//www.mendeley.com/funding/"
										class="header-mdata-nav-loggedout-nav-item">Funding</a></li>
							</ul>
						</nav>
						<nav class="header-mdata-nav header-mdata-nav-nonburger">
							<a href="/datasets" class="header-mdata-nav-item active">Find Research Data</a>
							<a href="/drafts" class="header-mdata-nav-item">My Datasets</a>
							<a href="/drafts/new" class="header-mdata-nav-item">New Dataset</a>
							<a href="/faq" class="header-mdata-nav-item">FAQ</a>
						</nav>
					</div>
				</div>
			</div>
		</header>

	</div>

	<div class="main">

		<div class="notifications" data-sticky-toolbar-body data-component="notifications">
			<div class="notifications-inner">
			</div>
		</div>



		<main role="main" id="maincontent" class="content">
			<div class="content-inner public-datasets-search">
				<div id="results">
					<div class="public-datasets-search__inner" data-reactroot="">
						<div class="public-datasets-search__form-wrapper">
							<div class="public-datasets-search__form">
								<div class="public-datasets-search__form-inner">
									<form method="GET" action="/datasets" class="datasets-form">
										<div class="datasets-form__input-wrapper">
											<input type="text" name="query" id="query" class="datasets-form__input" placeholder="Find Research Data" autoComplete="off" value="musical instruments"/><button type="submit" aria-label="Search" class="btn btn-secondary-inverse datasets-form__submit"><span class="icon icon-search-white"></span></button>
										</div>
										<div></div>
									</form>
								</div>
							</div>
						</div>
						<div class="public-datasets-search__results">
							<div class="search-results-details">
								<div>
									<button class="button btn btn-secondary btn-tight show-sidebar-btn"> Filters </button>
									<div class="sidebar">
										<nav class="sidebar__nav">
											<div>
												<div class="section-header facets__header">
													<button class="button facets__close"><span class="icon icon-x-accent"></span></button><a
														href="/datasets?query=musical instruments&amp;page=0"
														class="btn btn-secondary btn-tight facets__reset facets__reset--disabled">Reset</a>
													<h3 class="section-header-text facets__header-text"> Filter Results
													</h3>
												</div>
												<ul class="facets__list">
													<li>
														<div class="facet">
															<button class="facet__title" aria-expanded="true"><span>Data Types</span><span class="icon icon-chevron-up-accent"></span></button>
															<ul class="facet__items" id="type">
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=DOCUMENT"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Document
																			<!-- --> (
																			<!-- -->1427
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=OTHER"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Other
																			<!-- --> (
																			<!-- -->1134
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=IMAGE"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Image
																			<!-- --> (
																			<!-- -->544
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=DATASET"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Dataset
																			<!-- --> (
																			<!-- -->426
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=TABULAR_DATA"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Tabular Data
																			<!-- --> (
																			<!-- -->419
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=COLLECTION"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Collection
																			<!-- --> (
																			<!-- -->126
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=VIDEO"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Video
																			<!-- --> (
																			<!-- -->94
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=FILE_SET"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">File Set
																			<!-- --> (
																			<!-- -->68
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=AUDIO"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Audio
																			<!-- --> (
																			<!-- -->64
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=TEXT"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Text
																			<!-- --> (
																			<!-- -->8
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=PHYSICAL_OBJECT"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Physical Object
																			<!-- --> (
																			<!-- -->5
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=WORKFLOW"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Workflow
																			<!-- --> (
																			<!-- -->3
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=SLIDES"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Slides
																			<!-- --> (
																			<!-- -->2
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;type=SOFTWARE_CODE"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Software/Code
																			<!-- --> (
																			<!-- -->1
																			<!-- -->)</div>
																	</a></li>
															</ul>
														</div>
													</li>
													<li>
														<div class="facet">
															<button class="facet__title" aria-expanded="true"><span>Repository Types</span><span class="icon icon-chevron-up-accent"></span></button>
															<ul class="facet__items" id="repositoryType">
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;repositoryType=NON_ARTICLE_BASED_REPOSITORY"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Data
																			Repositories
																			<!-- --> (
																			<!-- -->3203
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;repositoryType=ARTICLE_BASED_REPOSITORY"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Article
																			Repositories
																			<!-- --> (
																			<!-- -->686
																			<!-- -->)</div>
																	</a></li>
															</ul>
														</div>
													</li>
													<li>
														<div class="facet">
															<button class="facet__title" aria-expanded="true"><span>Sources</span><span class="icon icon-chevron-up-accent"></span></button>
															<ul class="facet__items" id="source">
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ZENODO"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Zenodo
																			<!-- --> (
																			<!-- -->1189
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=SCIENCE_DIRECT"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">ScienceDirect
																			<!-- --> (
																			<!-- -->462
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=sage.dplanet"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Data Planet
																			<!-- --> (
																			<!-- -->361
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=usc.dl"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Southern California Digital Library
																			<!-- --> (
																			<!-- -->271
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cisti.ubc"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			British Columbia
																			<!-- --> (
																			<!-- -->115
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=figshare.ars"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">figshare
																			Academic Research System
																			<!-- --> (
																			<!-- -->113
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=psnc.pan-cc"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Czytelnia
																			Czasopism PAN
																			<!-- --> (
																			<!-- -->112
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ARXIV"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">arXiv
																			<!-- --> (
																			<!-- -->93
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cyberl.cyberdoi"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">CyberDOI
																			<!-- --> (
																			<!-- -->80
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=APOLLO"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Apollo Cambridge
																			<!-- --> (
																			<!-- -->78
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=gesis.icpsr"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">ICPSR
																			<!-- --> (
																			<!-- -->75
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ands.centre-3"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Monash
																			University
																			<!-- --> (
																			<!-- -->73
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=umd.lib"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Maryland Libraries Repositories
																			<!-- --> (
																			<!-- -->69
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=subgoe.vzg"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Verbundzentrale
																			des GBV
																			<!-- --> (
																			<!-- -->54
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=tib.kmo"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">TIB KMO /
																			FLOWWORKS GmbH
																			<!-- --> (
																			<!-- -->47
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=mla.hc"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Humanities
																			Commons
																			<!-- --> (
																			<!-- -->44
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cul.columbia"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Columbia
																			University Libraries
																			<!-- --> (
																			<!-- -->40
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=tib.univie"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Vienna
																			<!-- --> (
																			<!-- -->36
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ands.centre13"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">ANU Data Commons
																			<!-- --> (
																			<!-- -->28
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=rutgers.lib"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Rutgers
																			University Community Repository (RUcore)
																			<!-- --> (
																			<!-- -->27
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=tib.tub"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Technische
																			Universität Berlin – Universitätsbibliothek
																			<!-- --> (
																			<!-- -->26
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=DATASPACE"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">DataSpace
																			Princeton
																			<!-- --> (
																			<!-- -->24
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=uky.lib"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Kentucky Libraries
																			<!-- --> (
																			<!-- -->22
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=DSPACEUNIVERSITYOFWASHINGTON"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">DSpace
																			Washington
																			<!-- --> (
																			<!-- -->22
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=msu.libraries"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Michigan State
																			University Libraries
																			<!-- --> (
																			<!-- -->21
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cmu.kilthub"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">KiltHub
																			Repository
																			<!-- --> (
																			<!-- -->20
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=gdcc.odum-library"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">UNC Libraries
																			<!-- --> (
																			<!-- -->20
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cisti.uottawa"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Ottawa
																			<!-- --> (
																			<!-- -->19
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=figshare.sage"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">figshare SAGE
																			Publications
																			<!-- --> (
																			<!-- -->18
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=tib.fuub"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">
																			Universitätsbibliothek der FU Berlin
																			Hochschulschriftenstelle u. Dokumentenserver
																			<!-- --> (
																			<!-- -->16
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ICPSR"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">ICPSR
																			<!-- --> (
																			<!-- -->16
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.oxdb"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Oxford
																			University Library Service Databank
																			<!-- --> (
																			<!-- -->16
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=viva.uva-libra"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Virginia Libraries
																			<!-- --> (
																			<!-- -->14
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=crui.unipv"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Università degli
																			Studi di Pavia
																			<!-- --> (
																			<!-- -->14
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=heallink.ntua"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">National
																			Technical University of Athens (NTUA)
																			<!-- --> (
																			<!-- -->11
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.salford"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Salford
																			<!-- --> (
																			<!-- -->11
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cisti.ucalgary"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Calgary
																			<!-- --> (
																			<!-- -->11
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=cos.osf"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Open Science
																			Framework
																			<!-- --> (
																			<!-- -->8
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.dri"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Digital
																			Repository of Ireland
																			<!-- --> (
																			<!-- -->7
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=rstat.library"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">RoyaltyStat
																			Library
																			<!-- --> (
																			<!-- -->7
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=tib.tudo"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Technische
																			Universität Dortmund
																			<!-- --> (
																			<!-- -->7
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=nrct.db1"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">NRCT Data Center
																			<!-- --> (
																			<!-- -->7
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=NEURO_ELECTRO"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">NeuroElectro
																			<!-- --> (
																			<!-- -->7
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=crui.unibo"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Università degli
																			Studi di Bologna
																			<!-- --> (
																			<!-- -->6
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.gold"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Goldsmiths&#x27;
																			College
																			<!-- --> (
																			<!-- -->6
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.leeds"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">University of
																			Leeds
																			<!-- --> (
																			<!-- -->6
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=SMITHSONIANDIGITALREPOSITORY"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Smithsonian
																			<!-- --> (
																			<!-- -->5
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=bl.rcm"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Royal College of
																			Music
																			<!-- --> (
																			<!-- -->5
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=ands.centre66"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Australian
																			Catholic University
																			<!-- --> (
																			<!-- -->5
																			<!-- -->)</div>
																	</a></li>
																<li class="facet__item"><a tabindex="0"
																		class="facet__checkbox"
																		href="/datasets?query=musical instruments&amp;page=0&amp;source=crui.unile"
																		role="checkbox" aria-checked="false">
																		<div class="facet__checkbox-img">
																			<span class="icon icon-success-white"></span>
																		</div>
																		<div class="facet__item--title">Università del
																			Salento
																			<!-- --> (
																			<!-- -->5
																			<!-- -->)</div>
																	</a></li>
															</ul>
														</div>
													</li>
												</ul>
											</div>
											<button class="sidebar__back"> View <!-- -->3889<!-- --> Results </button>
										</nav>
									</div>
									<div class="results-content">
										<div class="search-results-listing">
											<div class="count section-header results-content__count">
												<h3 class="count__text">3889 results for musical instruments</h3>
											</div>
											<div class="search-results-listing__results">
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="https://zenodo.org/record/1176665"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">The Squiggle:
																		A Digital <strong>Musical</strong>
																		<strong>Instrument</strong></h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Sheehan, Brian</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2004-06-01</p>
																<p class="search-result__summary">This paper discusses
																	some of the issues pertaining to thedesign of
																	digital <strong>musical</strong>
																	<strong>instruments</strong> that are to effectively
																	fillthe role of traditional
																	<strong>instruments</strong> (i.e. those based on
																	physicalsound production mechanisms). The design
																	andimplementation of a <strong>musical</strong>
																	<strong>instrument</strong> that addresses some
																	ofthese issues, using scanned synthesis coupled to a
																	"smart"physical system, is described. ... This paper
																	discusses some of the issues pertaining to thedesign
																	of digital <strong>musical</strong>
																	<strong>instruments</strong> that are to effectively
																	fillthe role of traditional
																	<strong>instruments</strong> (i.e. those based on
																	physicalsound production mechanisms). The design
																	andimplementation of a <strong>musical</strong>
																	<strong>instrument</strong> that addresses some
																	ofthese issues, using scanned synthesis coupled to a
																	"smart"physical system, is described.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Document</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="http://cla.berkeley.edu/item/1549"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">[Notes on
																		<strong>musical</strong>
																		<strong>instruments</strong>]</h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Sawyer, Jesse O.</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2015-01-01</p>
																<p class="search-result__summary">Notes on
																	<strong>musical</strong>
																	<strong>instruments</strong> of indigenous
																	California. Includes photographs of each item, with
																	negatives. ... Notes on <strong>musical</strong>
																	<strong>instruments</strong> of indigenous
																	California. Includes photographs of each item, with
																	negatives.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Other</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="http://digitallibrary.usc.edu/cdm/ref/collection/p15799coll65/id/12489"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">Chinese
																		<strong>musical</strong>
																		<strong>instruments</strong></h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Pierce, C.C. (Charles C.), 1861-1946</span>
																</p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2012-01-01</p>
																<p class="search-result__summary">
																	<strong>Music</strong>...<strong>Musical</strong>
																	<strong>instruments</strong>...Photograph of 9
																	Chinese (or Hawaiian) <strong>musical</strong>
																	<strong>instruments</strong> on or near a small
																	bamboo table. There are 3 plucked-string
																	<strong>instruments</strong>, 2 wind
																	<strong>instruments</strong>, and the rest are
																	percussion <strong>instruments</strong>. Two painted
																	Japanese[?] placards hang from the panel behind the
																	table. ... Photograph of 9 Chinese (or Hawaiian)
																	<strong>musical</strong>
																	<strong>instruments</strong> on or near a small
																	bamboo table. There are 3 plucked-string
																	<strong>instruments</strong>, 2 wind
																	<strong>instruments</strong>, and the rest are
																	percussion <strong>instruments</strong>. Two painted
																	Japanese[?] placards hang from the panel behind the
																	table.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Dataset</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
													<div class="boosted-data-results-info">
														<p><span class="icon icon-chevron-up-dark"></span><span class="boosted-data-results-text">Top results from Data Repository sources.   </span><span><a class="boosted-data-results-link" href="/datasets?query=musical instruments&amp;page=0&amp;repositoryType=NON_ARTICLE_BASED_REPOSITORY" aria-label="Click here to show only results from data repos">Show only results like these.</a></span>
														</p>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="http://www.sciencedirect.com/science/article/pii/S0377-0427(00)00560-4"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">Eigenvalues
																		and <strong>musical</strong>
																		<strong>instruments</strong></h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>V.E Howle, Lloyd N Trefethen</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2001-10-01</p>
																<p class="search-result__summary">Eigenvalues of a minor
																	third A4? bell, measured in [18], as given in [14,
																	Table 5.3.1]. The grid lines show the positions of
																	the frequencies corresponding to a minor third chord
																	at 456.8Hz, together with two octaves above the
																	fundamental and one below. All six of these modes
																	are closely matched by eigenvalues of the bell, a
																	tribute to how far bell design has evolved over the
																	centuries to achieve a <strong>musical</strong>
																	effect. The eigenvalue picture for an unmusical
																	bell, such as one worn by a cow, would look utterly
																	different.
																	...<strong>Musical</strong>
																	<strong>instruments</strong>...Most
																	<strong>musical</strong>
																	<strong>instruments</strong> are built from physical
																	systems that oscillate at certain natural
																	frequencies. The frequencies are the imaginary parts
																	of the eigenvalues of a linear operator, and the
																	decay rates are the negatives of the real parts, so
																	it ought to be possible to give an approximate idea
																	of the sound of a <strong>musical</strong>
																	<strong>instrument</strong> by a single plot of
																	points in the complex plane. Nevertheless, the
																	authors are unaware of any such picture that has
																	ever appeared in print. This paper attempts to fill
																	that gap by plotting eigenvalues for simple models
																	of a guitar string, a flute, a clarinet, a
																	kettledrum, and a <strong>musical</strong> bell. For
																	the drum and the bell, simple idealized models have
																	eigenvalues that are irrationally related, but as
																	the actual <strong>instruments</strong> have evolved
																	over the generations, the leading five or six
																	eigenvalues have moved around the complex plane so
																	that their relative positions are
																	<strong>musically</strong> pleasing. ... Most
																	<strong>musical</strong>
																	<strong>instruments</strong> are built from physical
																	systems that oscillate at certain natural
																	frequencies. The frequencies are the imaginary parts
																	of the eigenvalues of a linear operator, and the
																	decay rates are the negatives of the real parts, so
																	it ought to be possible to give an approximate idea
																	of the sound of a <strong>musical</strong>
																	<strong>instrument</strong> by a single plot of
																	points in the complex plane. Nevertheless, the
																	authors are unaware of any such picture that has
																	ever appeared in print. This paper attempts to fill
																	that gap by plotting eigenvalues for simple models
																	of a guitar string, a flute, a clarinet, a
																	kettledrum, and a <strong>musical</strong> bell. For
																	the drum and the bell, simple idealized models have
																	eigenvalues that are irrationally related, but as
																	the actual <strong>instruments</strong> have evolved
																	over the generations, the leading five or six
																	eigenvalues have moved around the complex plane so
																	that their relative positions are
																	<strong>musically</strong> pleasing.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Image</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="http://www.sciencedirect.com/science/article/pii/S0264-1275(15)30533-5"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">Carbon fiber
																		material in <strong>musical</strong>
																		<strong>instrument</strong> making</h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Ze Hong Wu, Jia Hui Li</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2016-01-05</p>
																<p class="search-result__summary">Scientists have been
																	trying to make <strong>musical</strong>
																	<strong>instruments</strong> with novel materials in
																	recent years. In this research, we set up a system
																	to test carbon fiber <strong>musical</strong>
																	<strong>instruments</strong>. A carbon fiber cello
																	was successfully prepared and its sound quality was
																	measured by Chladni experiment and Fourier analysis.
																	The criterion of <strong>musical</strong> sound by
																	Fourier analysis is defined and demonstrated.
																	According to this research, carbon fiber was indeed
																	a good novel material in <strong>musical</strong>
																	<strong>instruments</strong> making with the
																	significance of technological process, environmental
																	sustainability and art....Novel
																	<strong>musical</strong> <strong>instrument</strong>
																	... Scientists have been trying to make
																	<strong>musical</strong>
																	<strong>instruments</strong> with novel materials in
																	recent years. In this research, we set up a system
																	to test carbon fiber <strong>musical</strong>
																	<strong>instruments</strong>. A carbon fiber cello
																	was successfully prepared and its sound quality was
																	measured by Chladni experiment and Fourier analysis.
																	The criterion of <strong>musical</strong> sound by
																	Fourier analysis is defined and demonstrated.
																	According to this research, carbon fiber was indeed
																	a good novel material in <strong>musical</strong>
																	<strong>instruments</strong> making with the
																	significance of technological process, environmental
																	sustainability and art.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Image</span></span>
																		</li>
																		<li class="search-result__tag">
																			<span class="tag"><span>Tabular Data</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="http://www.sciencedirect.com/science/article/pii/S1053-8119(11)00221-7"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">
																		Neuroplasticity of semantic representations for
																		<strong>musical</strong>
																		<strong>instruments</strong> in professional
																		musicians</h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Klaus Hoenig, Cornelia Müller, Bärbel Herrnberger, Eun-Jin Sim, Manfred Spitzer, Günter Ehret, Markus Kiefer</span>
																</p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2011-06-01</p>
																<p class="search-result__summary">Sensorimotor
																	conceptual enrichment. Increased relevance ratings
																	of acoustic, visual, and motor features for
																	<strong>musical</strong>
																	<strong>instruments</strong> in musicians (N=20)
																	compared to non-musicians (N=20), demonstrating the
																	conceptual enrichment for <strong>musical</strong>
																	<strong>instruments</strong> due to the intensive
																	sensorimotor experiences of musicians with these
																	objects. p&lt;0.001 for each of the post-hoc
																	comparisons between musicians and non-musicians;
																	small vertical bars indicate the standard error of
																	means (s.e.m.).
																	...Perceptual processing of real sounds and overlap
																	between auditory perceptual and conceptual brain
																	activation. A, Perceptual task: Activation during
																	listening to real sounds, pmusical
																	<strong>instruments</strong> compared to control
																	objects in musicians (N=20), but not in
																	non-musicians (N=20; pacoustic noise) and the
																	conceptual group-by-object interaction (group:
																	musicians&gt;non-musicians, object:
																	<strong>musical</strong>
																	<strong>instruments</strong> (MI)&gt;control objects
																	(CO)), respectively. Shown are contiguous slices
																	centered on the peak coordinates (68–42 0) obtained
																	from the interaction analysis of the conceptual
																	task. P=posterior, A=anterior,
																	MI=<strong>musical</strong>
																	<strong>instruments</strong>, CO=control objects.
																	...Norming results of the stimulus material. Shown
																	are the average values of the behavioral ratings for
																	the relevance of acoustic (Ac), visual (Vis), and
																	motor (Mot) features as well as of emotional valence
																	(Emot), familiarity (Fam) and visual complexity
																	(Vcom) of the pictures for <strong>musical</strong>
																	<strong>instruments</strong> and control objects.
																	Data were obtained from an independent prior norming
																	study. <strong>Musical</strong>
																	<strong>instruments</strong> and control objects
																	differed only with respect to acoustic concept
																	features. ***p&lt;0.001; small vertical bars
																	indicate the standard error of means (s.e.m.).
																	...Professional musicians constitute a model par
																	excellence for understanding experience-dependent
																	plasticity in the human brain, particularly in the
																	auditory domain. Their intensive sensorimotor
																	experience with <strong>musical</strong>
																	<strong>instruments</strong> has been shown to
																	entail plastic brain alterations in cortical
																	perceptual and motor maps. It remains an important
																	question whether this neuroplasticity might extend
																	beyond basic perceptual and motor functions and even
																	shape higher-level conceptualizations by which we
																	conceive our physical and social world. Here we show
																	using functional magnetic resonance imaging (fMRI)
																	that conceptual processing of visually presented
																	<strong>musical</strong>
																	<strong>instruments</strong> activates auditory
																	association cortex encompassing right posterior
																	superior temporal gyrus, as well as adjacent areas
																	in the superior temporal sulcus and the upper part
																	of middle temporal gyrus (pSTG/MTG) only in
																	musicians, but not in <strong>musical</strong>
																	laypersons. These areas in and adjacent to auditory
																	association cortex were not only recruited by
																	conceptual processing of <strong>musical</strong>
																	<strong>instruments</strong> during visual object
																	recognition, but also by auditory perception of real
																	sounds. Hence, the unique intensive experience of
																	musicians with <strong>musical</strong>
																	<strong>instruments</strong> establishes a link
																	between auditory perceptual and conceptual brain
																	systems. Experience-driven neuroplasticity in
																	musicians is thus not confined to alterations of
																	perceptual and motor maps, but even leads to the
																	establishment of higher-level semantic
																	representations for <strong>musical</strong>
																	<strong>instruments</strong> in and adjacent to
																	auditory association cortex. These findings
																	highlight the eminent importance of sensory and
																	motor experience for acquiring rich
																	concepts....Functional interaction effects between
																	Group (musicians vs. non-musicians) and Object
																	(<strong>musical</strong>
																	<strong>instruments</strong> vs. control objects).
																	A, Multi-slice view of increased functional
																	activation to <strong>musical</strong>
																	<strong>instruments</strong> compared to control
																	objects for musicians (N=20) compared with
																	non-musicians (N=20), pmusical
																	<strong>instruments</strong> and control objects to
																	brain activation at the peak voxel of the respective
																	cluster for musicians and non-musicians.
																	...Functional brain activation pertaining to
																	acoustic conceptual features of
																	<strong>musical</strong>
																	<strong>instruments</strong>. A, Brain activation of
																	the conceptual group-by-object contrast: Increased
																	activation to <strong>musical</strong>
																	<strong>instruments</strong> compared to control
																	objects for musicians (N=20) compared with
																	non-musicians (N=20) in right pSTG/MTG, pmusical
																	<strong>instruments</strong> and control objects to
																	brain activation at the peak voxel of the pSTG/MTG
																	cluster for musicians and non-musicians. The bar
																	chart shows that the interaction effect is due to a
																	differentially larger activation increase for
																	<strong>musical</strong>
																	<strong>instruments</strong> compared with control
																	objects in musicians than in non-musicians.
																	P=posterior, A=anterior, L=left, R=right.
																	... Professional musicians constitute a model par
																	excellence for understanding experience-dependent
																	plasticity in the human brain, particularly in the
																	auditory domain. Their intensive sensorimotor
																	experience with <strong>musical</strong>
																	<strong>instruments</strong> has been shown to
																	entail plastic brain alterations in cortical
																	perceptual and motor maps. It remains an important
																	question whether this neuroplasticity might extend
																	beyond basic perceptual and motor functions and even
																	shape higher-level conceptualizations by which we
																	conceive our physical and social world. Here we show
																	using functional magnetic resonance imaging (fMRI)
																	that conceptual processing of visually presented
																	<strong>musical</strong>
																	<strong>instruments</strong> activates auditory
																	association cortex encompassing right posterior
																	superior temporal gyrus, as well as adjacent areas
																	in the superior temporal sulcus and the upper part
																	of middle temporal gyrus (pSTG/MTG) only in
																	musicians, but not in <strong>musical</strong>
																	laypersons. These areas in and adjacent to auditory
																	association cortex were not only recruited by
																	conceptual processing of <strong>musical</strong>
																	<strong>instruments</strong> during visual object
																	recognition, but also by auditory perception of real
																	sounds. Hence, the unique intensive experience of
																	musicians with <strong>musical</strong>
																	<strong>instruments</strong> establishes a link
																	between auditory perceptual and conceptual brain
																	systems. Experience-driven neuroplasticity in
																	musicians is thus not confined to alterations of
																	perceptual and motor maps, but even leads to the
																	establishment of higher-level semantic
																	representations for <strong>musical</strong>
																	<strong>instruments</strong> in and adjacent to
																	auditory association cortex. These findings
																	highlight the eminent importance of sensory and
																	motor experience for acquiring rich concepts.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Image</span></span>
																		</li>
																		<li class="search-result__tag">
																			<span class="tag"><span>Tabular Data</span></span>
																		</li>
																		<li class="search-result__tag">
																			<span class="tag"><span>Document</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="https://zenodo.org/record/1555663"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">The
																		<strong>Music</strong> and
																		<strong>Musical</strong>
																		<strong>Instruments</strong> of the Bible</h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Schlesinger, Kathleen, Stainer, John</span>
																</p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->1914-06-01</p>
																<p class="search-result__summary"> ... n/a</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Document</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="https://zenodo.org/record/1178147"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">MelodyMorph:
																		A Reconfigurable <strong>Musical</strong>
																		<strong>Instrument</strong></h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Rosenbaum, Eric</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2011-06-01</p>
																<p class="search-result__summary">I present MelodyMorph,
																	a reconfigurable <strong>musical</strong>
																	<strong>instrument</strong> designed with a focus on
																	melodic improvisation. It is designed for a
																	touch-screen interface, and allows the user to
																	create "bells" which can be tapped to play a note,
																	and dragged around on a pannable and zoomable
																	canvas. Colors, textures and shapes of the bells
																	represent pitch and timbre properties. "Recorder
																	bells" can store and play back performances. Users
																	can construct <strong>instruments</strong> that are
																	modifiable as they play, and build up complex
																	melodies hierarchically from simple parts. ... I
																	present MelodyMorph, a reconfigurable
																	<strong>musical</strong> <strong>instrument</strong>
																	designed with a focus on melodic improvisation. It
																	is designed for a touch-screen interface, and allows
																	the user to create "bells" which can be tapped to
																	play a note, and dragged around on a pannable and
																	zoomable canvas. Colors, textures and shapes of the
																	bells represent pitch and timbre properties.
																	"Recorder bells" can store and play back
																	performances. Users can construct
																	<strong>instruments</strong> that are modifiable as
																	they play, and build up complex melodies
																	hierarchically from simple parts.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Document</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="https://doi.org/10.18130/V3/DQQZOG"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">
																		Bellona_Jon_2018_PhD_Distance-X_software</h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Bellona, Jon</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2018-04-27</p>
																<p class="search-result__summary">Software of
																	Distance-X, a custom built alternate controller
																	digital <strong>musical</strong>
																	<strong>instrument</strong>. All software related to
																	Jon Bellona's 2018 PhD Dissertation entitled,
																	Physical Composition: The
																	<strong>Musicality</strong> of Body Movement on
																	Digital <strong>Musical</strong>
																	<strong>Instruments</strong>....Software for
																	Distance-X, a custom built alternate controller
																	digital <strong>musical</strong>
																	<strong>instrument</strong>. All software related to
																	Jon Bellona's 2018 PhD Dissertation entitled,
																	Physical Composition: The
																	<strong>Musicality</strong> of Body Movement on
																	Digital <strong>Musical</strong>
																	<strong>Instruments</strong>....<strong>Music</strong>
																	... Software of Distance-X, a custom built alternate
																	controller digital <strong>musical</strong>
																	<strong>instrument</strong>. All software related to
																	Jon Bellona's 2018 PhD Dissertation entitled,
																	Physical Composition: The
																	<strong>Musicality</strong> of Body Movement on
																	Digital <strong>Musical</strong>
																	<strong>Instruments</strong>.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Image</span></span>
																		</li>
																		<li class="search-result__tag">
																			<span class="tag"><span>File Set</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
												<div>
													<div class="search-result">
														<div class="search-result__content">
															<div class="search-result__header">
																<div class="search-result__thumbnail"></div><a
																	target="_blank"
																	href="https://zenodo.org/record/1180321"
																	class="search-result__header-link">
																	<h3 class="search-result__header-text">MelodyMorph:
																		A Reconfigurable <strong>Musical</strong>
																		<strong>Instrument</strong></h3>
																</a>
															</div>
															<div class="search-result__details">
																<p class="search-result__contributors">
																	<span class="search-result__contributors-heading">Contributors:</span>
																	<span>Rosenbaum, Eric</span></p>
																<p class="search-result__date">
																	<span class="search-result__date-heading">Date:</span>
																	<!-- -->2011-06-01</p>
																<p class="search-result__summary">I present MelodyMorph,
																	a reconfigurable <strong>musical</strong>
																	<strong>instrument</strong> designed with a focus on
																	melodic improvisation. It is designed for a
																	touch-screen interface, and allows the user to
																	create "bells" which can be tapped to play a note,
																	and dragged around on a pannable and zoomable
																	canvas. Colors, textures and shapes of the bells
																	represent pitch and timbre properties. "Recorder
																	bells" can store and play back performances. Users
																	can construct <strong>instruments</strong> that are
																	modifiable as they play, and build up complex
																	melodies hierarchically from simple parts. ... I
																	present MelodyMorph, a reconfigurable
																	<strong>musical</strong> <strong>instrument</strong>
																	designed with a focus on melodic improvisation. It
																	is designed for a touch-screen interface, and allows
																	the user to create "bells" which can be tapped to
																	play a note, and dragged around on a pannable and
																	zoomable canvas. Colors, textures and shapes of the
																	bells represent pitch and timbre properties.
																	"Recorder bells" can store and play back
																	performances. Users can construct
																	<strong>instruments</strong> that are modifiable as
																	they play, and build up complex melodies
																	hierarchically from simple parts.</p>
																<div>
																	<p class="search-result__files">Data types:</p>
																	<ul class="search-result__tags">
																		<li class="search-result__tag">
																			<span class="tag"><span>Other</span></span>
																		</li>
																	</ul>
																</div>
															</div>
														</div>
													</div>
												</div>
											</div>
										</div>
									</div>
								</div>
								<div>
									<div class="pager" role="navigation" aria-label="Pagination">
										<span class="pager__page-num pager__page-num--active"><a>1</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=1">2</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=2">3</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=3">4</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=4">5</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=5">6</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=6">7</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=7">8</a></span><span class="pager__page-num"><a href="/datasets?query=musical instruments&amp;page=8">9</a></span><span class="pager__next pager__nav"><a href="/datasets?query=musical instruments&amp;page=1">Next<span class="icon icon-chevron-right-accent"></span></a></span>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
				<script>
					window.REACT_DATA = {"predefinedState":{"datasearchResults":{"results":[{"id":"053054054054055049049058103114111046111100111110101122058105097111:ZENODO","externalId":"oai:zenodo.org:1176665","containerTitle":"The Squiggle: A Digital \u003cstrong>Musical\u003c/strong> \u003cstrong>Instrument\u003c/strong>","source":"ZENODO","containerType":"article","lastImported":"2018-12-08T00:00:00Z","externalContainerType":"info:eu-repo/semantics/conferencePaper,publication-conferencepaper,","containerDescription":"This paper discusses some of the issues pertaining to thedesign of digital \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> that are to effectively fillthe role of traditional \u003cstrong>instruments\u003c/strong> (i.e. those based on physicalsound production mechanisms). The design andimplementation of a \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> that addresses some ofthese issues, using scanned synthesis coupled to a \"smart\"physical system, is described.","doi":"doi:10.5281/zenodo.1176665","publicationDate":"2004-06-01","containerDataTypes":["DOCUMENT"],"dateAvailable":"2018-12-07","externalDateModified":"2018-12-07","repoType":"NON_ARTICLE_BASED_REPOSITORY","accessRights":"info:eu-repo/semantics/openAccess","containerURI":"https://zenodo.org/record/1176665","subjectAreas":["Physics"],"authors":[{"name":"Sheehan, Brian"}],"relatedResources":["doi:10.5281/zenodo.1176664","url:https://zenodo.org/communities/nime_conference"],"assetTypes":["DOCUMENT"],"snippets":["This paper discusses some of the issues pertaining to thedesign of digital \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> that are to effectively fillthe role of traditional \u003cstrong>instruments\u003c/strong> (i.e. those based on physicalsound production mechanisms). The design andimplementation of a \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> that addresses some ofthese issues, using scanned synthesis coupled to a \"smart\"physical system, is described."],"rsindex":1},{"id":"110113050050049118050120047055057050055046048049:cdl.ucb","externalId":"10.7297/x2v122qn","containerTitle":"[Notes on \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>]","source":"cdl.ucb","lastImported":"2020-01-15T15:15:57Z","containerDescription":"Notes on \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> of indigenous California. Includes photographs of each item, with negatives.","doi":"doi:10.7297/x2v122qn","publicationDate":"2015-01-01","containerDataTypes":["OTHER"],"repoType":"NON_ARTICLE_BASED_REPOSITORY","accessRights":"Items catalogued in the California Language Archive are the physical property of their respective physical repositories. Intellectual rights, including copyright, belong to item creators or their legal heirs and assigns.","containerURI":"http://cla.berkeley.edu/item/1549","authors":[{"name":"Sawyer, Jesse O."}],"assetTypes":[],"snippets":["Notes on \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> of indigenous California. Includes photographs of each item, with negatives."],"rsindex":2},{"id":"049053051048049109045115104099047057052053053050046048049:usc.dl","externalId":"10.25549/chs-m10351","containerTitle":"Chinese \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>","source":"usc.dl","lastImported":"2020-01-16T00:41:03Z","containerDescription":"Photograph of 9 Chinese (or Hawaiian) \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> on or near a small bamboo table. There are 3 plucked-string \u003cstrong>instruments\u003c/strong>, 2 wind \u003cstrong>instruments\u003c/strong>, and the rest are percussion \u003cstrong>instruments\u003c/strong>. Two painted Japanese[?] placards hang from the panel behind the table.","doi":"doi:10.25549/chs-m10351","publicationDate":"2012-01-01","containerDataTypes":["DATASET"],"repoType":"NON_ARTICLE_BASED_REPOSITORY","containerURI":"http://digitallibrary.usc.edu/cdm/ref/collection/p15799coll65/id/12489","externalSubjectAreas":["Minorities -- Chinese","Musical instruments","Music","Chinese Americans"],"authors":[{"name":"Pierce, C.C. (Charles C.), 1861-1946"}],"assetTypes":[],"snippets":["\u003cstrong>Music\u003c/strong>","\u003cstrong>Musical\u003c/strong> \u003cstrong>instruments\u003c/strong>","Photograph of 9 Chinese (or Hawaiian) \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> on or near a small bamboo table. There are 3 plucked-string \u003cstrong>instruments\u003c/strong>, 2 wind \u003cstrong>instruments\u003c/strong>, and the rest are percussion \u003cstrong>instruments\u003c/strong>. Two painted Japanese[?] placards hang from the panel behind the table."],"rsindex":3},{"institution":["Center for Applied Mathematics, 657 Frank H. T. Rhodes Hall, Cornell University, Ithaca, NY 14853, USA","Oxford University Computing Laboratory, Wolfson Building, Parks Road, Oxford OX1 3QD, UK"],"id":"052045048054053048048041048048040055050052048045055055051048083:SCIENCE_DIRECT","externalId":"S0377-0427(00)00560-4","containerTitle":"Eigenvalues and \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>","source":"SCIENCE_DIRECT","containerType":"article","lastImported":"2018-08-20T00:00:00Z","externalContainerType":"CAM","containerDescription":"Most \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> are built from physical systems that oscillate at certain natural frequencies. The frequencies are the imaginary parts of the eigenvalues of a linear operator, and the decay rates are the negatives of the real parts, so it ought to be possible to give an approximate idea of the sound of a \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> by a single plot of points in the complex plane. Nevertheless, the authors are unaware of any such picture that has ever appeared in print. This paper attempts to fill that gap by plotting eigenvalues for simple models of a guitar string, a flute, a clarinet, a kettledrum, and a \u003cstrong>musical\u003c/strong> bell. For the drum and the bell, simple idealized models have eigenvalues that are irrationally related, but as the actual \u003cstrong>instruments\u003c/strong> have evolved over the generations, the leading five or six eigenvalues have moved around the complex plane so that their relative positions are \u003cstrong>musically\u003c/strong> pleasing.","doi":"doi:10.1016/S0377-0427(00)00560-4","publicationDate":"2001-10-01","containerDataTypes":["IMAGE"],"dateAvailable":"1998-10-06","externalDateModified":"2000-05-05","repoType":"ARTICLE_BASED_REPOSITORY","version":"4.5.2","accessRights":"Elsevier Science B.V.","contact":"vehowle@ca.sandia.gov, Corresponding author. Present address: Sandia National Laboratories, MS 9217, P.O. Box 969, Livermore, CA 94551, USA","howToCite":"http://dx.doi.org/10.1016/S0377-0427(00)00560-4","containerURI":"http://www.sciencedirect.com/science/article/pii/S0377-0427(00)00560-4","subjectAreas":["Classical Physics"],"containerKeywords":["Musical instruments","Normal modes","Drum","Eigenvalues","Recorder","Bell"],"authors":[{"name":"V.E Howle"},{"name":"Lloyd N Trefethen"}],"references":["References[1]A.H.BenadeOn woodwind instrument boresJ. Acoust. Soc. Amer.311959137146[2]A.H.BenadeHorns, Strings, and Harmony1960Anchor Books Doubleday & CoNew York[3]A.H. Benade, Fundamentals of Musical Acoustics (1977, 2nd Revised Edition), Dover, New York, 1990.[4]R.S.ChristianR.E.DavisA.TubisC.A.AndersonR.I.MillsT.D.RossingEffects of air loading on timpani membrane vibrationsJ. Acoust. Soc. Amer.76198413361345[5]N.H.FletcherPlucked strings — a reviewJ. Catgut Acoust. Soc.2619761317[6]H.FletcherI.G.BassettSome experiments with the bass drumJ. Acoust. Soc. Amer.64197815701576[7]N.H.FletcherT.D.RossingThe physics of musical instruments1991SpringerNew York[8]M.HancockThe dynamics of musical strings [1]J. Catgut Acoust. Soc., 2nd Ser.119893345[9]J.R.KuttlerV.G.SigillitaEigenvalues of the Laplacian in two dimensionsSIAM Rev.261984163193[10]P.M.MorseVibration and Sound1948McGraw-HillNew York[11]B.E. Berg, Sound, in: The New Encyclopaedia Britannica, Macropaedia, Vol. 27, 15th Edition, Helen Hemingway Benton, Chicago, 1991, pp. 604–627.[12]N.C.PickeringPhysical properties of violin stringsJ. Catgut Acoust. Soc.44198568[13]J.W.S. Rayleigh, The Theory of Sound, Vol. I, 2nd Edition (1894; reprinted ed.) Dover, New York, 1945.[14]P.J.M. Roozen-Kroon, Structural optimization of bells, Ph.D. Thesis, Technische Universiteit Eindhoven, 1992.[15]T.D.RossingAcoustics of percussion instruments — Part IIThe Phys. Teacher151977278288[16]T.D.RossingThe Physics of KettledrumsSci. Amer.2471982172178[17]F.W.SearsMechanics, Heat, and Sound2nd Edition1958Addison–WesleyReading, MA[18]F.H.SlaymakerW.F.MeekerMeasurements of the tonal characteristics of carillon bellsJ. Acoust. Soc. Amer.261954515522"],"assetTypes":["IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE"],"snippets":["Eigenvalues of a minor third A4? bell, measured in [18], as given in [14, Table 5.3.1]. The grid lines show the positions of the frequencies corresponding to a minor third chord at 456.8Hz, together with two octaves above the fundamental and one below. All six of these modes are closely matched by eigenvalues of the bell, a tribute to how far bell design has evolved over the centuries to achieve a \u003cstrong>musical\u003c/strong> effect. The eigenvalue picture for an unmusical bell, such as one worn by a cow, would look utterly different.\n","\u003cstrong>Musical\u003c/strong> \u003cstrong>instruments\u003c/strong>","Most \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> are built from physical systems that oscillate at certain natural frequencies. The frequencies are the imaginary parts of the eigenvalues of a linear operator, and the decay rates are the negatives of the real parts, so it ought to be possible to give an approximate idea of the sound of a \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> by a single plot of points in the complex plane. Nevertheless, the authors are unaware of any such picture that has ever appeared in print. This paper attempts to fill that gap by plotting eigenvalues for simple models of a guitar string, a flute, a clarinet, a kettledrum, and a \u003cstrong>musical\u003c/strong> bell. For the drum and the bell, simple idealized models have eigenvalues that are irrationally related, but as the actual \u003cstrong>instruments\u003c/strong> have evolved over the generations, the leading five or six eigenvalues have moved around the complex plane so that their relative positions are \u003cstrong>musically\u003c/strong> pleasing."],"rsindex":4},{"institution":["High School Affiliated to University of Shanghai Science and Technology, No. 247, Shui Feng Road, Yangpu District, Shanghai 200093, PR China","No. 2 Secondary School Attached to East China Normal University, No. 555, Chen Hui Road, Pudong New District, Shanghai 201203, PR China","East China University of Science and Technology, No.130, Mei Long Road, Xuhui District, Shanghai, 200237, PR China"],"id":"053045051051053048051041053049040053055050049045052054050048083:SCIENCE_DIRECT","externalId":"S0264-1275(15)30533-5","containerTitle":"Carbon fiber material in \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> making","source":"SCIENCE_DIRECT","containerType":"article","lastImported":"2018-08-19T00:00:00Z","externalContainerType":"JMADE","containerDescription":"Scientists have been trying to make \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> with novel materials in recent years. In this research, we set up a system to test carbon fiber \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>. A carbon fiber cello was successfully prepared and its sound quality was measured by Chladni experiment and Fourier analysis. The criterion of \u003cstrong>musical\u003c/strong> sound by Fourier analysis is defined and demonstrated. According to this research, carbon fiber was indeed a good novel material in \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> making with the significance of technological process, environmental sustainability and art.","doi":"doi:10.1016/j.matdes.2015.09.124","publicationDate":"2016-01-05","containerDataTypes":["IMAGE","TABULAR_DATA"],"dateCreated":"2015-09-21","dateAvailable":"2015-03-02","externalDateModified":"2015-09-20","repoType":"ARTICLE_BASED_REPOSITORY","version":"5.4","accessRights":"Elsevier Ltd","contact":"jiahuili@ecnu.edu.cn, Corresponding author at: No. 2 Secondary School Attached to East China Normal University, No. 555, Chen Hui Road, Pudong New District, Shanghai 201203, PR China. Tel.: +86 13918302276.","howToCite":"http://dx.doi.org/10.1016/j.matdes.2015.09.124","containerURI":"http://www.sciencedirect.com/science/article/pii/S0264-1275(15)30533-5","subjectAreas":["Physics"],"containerKeywords":["Cello","Novel musical instrument","Carbon fiber","Environmental protection"],"authors":[{"name":"Ze Hong Wu"},{"name":"Jia Hui Li"}],"references":["References[1]H.L.LuoPreparation and performance of long carbon fiber reinforced polyamide 6 composites injection-molded from core/shell structured pelletsMater. Des.642014294300[2]H.A.AlhashmyM.NganbeLaminate squeeze casting of carbon fiber reinforced aluminum matrix compositesMater. Des.672015154158[3]Y.G.ChenViolin Making and Repairing482002Shanghai Educ. Publ[4]I.CurtuThe structural analyses of classical guitar body through experimental methodsAnnu. DAAAM & Proc.200917891790[5]S.DubnovM.J.HinichAnalyzing several musical instrument tones using the randomly modulated periodicity modelSignal Proc.20092430[6]G.H.DuFundamentals of acoustics2012Nanjing Univ. Press28[7]H.-M.ZhangThe meaning of the theory of sound in the cello playing and performance skillsJ. Xinghai Conser. Music3200685[8]H.F.YangCarbon fiber industry in China into the development of the fast laneNew Mater. Ind.1200230[10]X.P.LiThe development and application status of carbon fiberHi-Tech Fiber Appl.305200525[11]J.J.MengJ.J.ZhuChinese fiddle industry status quo snapsMusical Instrum.7200111[12]M.J.QinZ.J.LiIntroduction to modern means of science and technology in the application of the instrumentMusical Instrum.5200421[15]X.M.JiangInstrument timber resources present situation, the thinking and countermeasures in our countryMusical Instrum.2200867[16]E.F.YangThe discussion of paulownia sound boardMusical Instrum.720081517[17]W.F.YuMan-made board as instruments materials development present situation and prospectsWood Proc. Mach.6201033"],"assetTypes":["IMAGE","IMAGE","TABULAR_DATA","TABULAR_DATA","TABULAR_DATA","IMAGE","IMAGE","IMAGE","IMAGE"],"snippets":["Scientists have been trying to make \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> with novel materials in recent years. In this research, we set up a system to test carbon fiber \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>. A carbon fiber cello was successfully prepared and its sound quality was measured by Chladni experiment and Fourier analysis. The criterion of \u003cstrong>musical\u003c/strong> sound by Fourier analysis is defined and demonstrated. According to this research, carbon fiber was indeed a good novel material in \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> making with the significance of technological process, environmental sustainability and art.","Novel \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong>"],"rsindex":5},{"institution":["University of Ulm, Department of Psychiatry, Section for Cognitive Electrophysiology, Leimgrubenweg 12, 89075 Ulm, Germany","University of Ulm, Institute of Neurobiology, Ulm, Germany"],"id":"055045049050050048048041049049040057049049056045051053048049083:SCIENCE_DIRECT","externalId":"S1053-8119(11)00221-7","containerTitle":"Neuroplasticity of semantic representations for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> in professional musicians","source":"SCIENCE_DIRECT","containerType":"article","lastImported":"2018-08-22T00:00:00Z","externalContainerType":"YNIMG","containerDescription":"Professional musicians constitute a model par excellence for understanding experience-dependent plasticity in the human brain, particularly in the auditory domain. Their intensive sensorimotor experience with \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> has been shown to entail plastic brain alterations in cortical perceptual and motor maps. It remains an important question whether this neuroplasticity might extend beyond basic perceptual and motor functions and even shape higher-level conceptualizations by which we conceive our physical and social world. Here we show using functional magnetic resonance imaging (fMRI) that conceptual processing of visually presented \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> activates auditory association cortex encompassing right posterior superior temporal gyrus, as well as adjacent areas in the superior temporal sulcus and the upper part of middle temporal gyrus (pSTG/MTG) only in musicians, but not in \u003cstrong>musical\u003c/strong> laypersons. These areas in and adjacent to auditory association cortex were not only recruited by conceptual processing of \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> during visual object recognition, but also by auditory perception of real sounds. Hence, the unique intensive experience of musicians with \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> establishes a link between auditory perceptual and conceptual brain systems. Experience-driven neuroplasticity in musicians is thus not confined to alterations of perceptual and motor maps, but even leads to the establishment of higher-level semantic representations for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> in and adjacent to auditory association cortex. These findings highlight the eminent importance of sensory and motor experience for acquiring rich concepts.","doi":"doi:10.1016/j.neuroimage.2011.02.065","publicationDate":"2011-06-01","containerDataTypes":["IMAGE","TABULAR_DATA","DOCUMENT"],"dateCreated":"2011-02-22","dateAvailable":"2010-06-23","externalDateModified":"2011-01-26","repoType":"ARTICLE_BASED_REPOSITORY","version":"5.1","accessRights":"Elsevier Inc.","contact":"Klaus.Hoenig@uni-ulm.de, Corresponding author. Fax: +49 731 500 61542.","howToCite":"http://dx.doi.org/10.1016/j.neuroimage.2011.02.065","containerURI":"http://www.sciencedirect.com/science/article/pii/S1053-8119(11)00221-7","subjectAreas":["Psychology"],"containerKeywords":["Conceptual neuroplasticity","fMRI","Language","Embodied cognition","Auditory cortex"],"authors":[{"name":"Klaus Hoenig"},{"name":"Cornelia Müller"},{"name":"Bärbel Herrnberger"},{"name":"Eun-Jin Sim"},{"name":"Manfred Spitzer"},{"name":"Günter Ehret"},{"name":"Markus Kiefer"}],"references":["ReferencesAltenmüller, 2001E.O.AltenmüllerHow many music centers are in the brain?Ann. NY Acad. Sci.9302001273280Anderson, 1983J.R.AndersonThe Architecture of Cognition1983Harvard University PressCambridge, MABao et al., 2004S.BaoE.F.ChangJ.WoodsM.M.MerzenichTemporal plasticity in the primary auditory cortex induced by operant perceptual learningNat. Neurosci.72004974981Barsalou and Wiemer-Hastings, 2005L.W.BarsalouK.Wiemer-HastingsSituating abstract conceptsD.PecherR.ZwaanThe Role of Perception and Action in Memory, Language, and Thought2005Cambridge University PressNew York129163Barsalou et al., 2003L.W.BarsalouW.SimmonsA.K.BarbeyC.D.WilsonGrounding conceptual knowledge in modality-specific systemsTrends Cogn. Sci.720038491Barsalou et al., 2008L.W.BarsalouA.SantosW.K.SimmonsC.D.WilsonLanguage and simulation in conceptual processingM.De VegaA.M.GlenbergA.C.GraesserSymbols, Embodiment, and Meaning2008Oxford University PressOxford245283Beilock et al., 2008S.L.BeilockI.M.LyonsA.Mattarella-MickeH.C.NusbaumS.L.SmallSports experience changes the neural processing of action languageProc. Natl. Acad. Sci. USA10520081326913273Belin et al., 2000P.BelinR.J.ZatorreP.LafailleP.AhadB.PikeVoice-selective areas in human auditory cortexNature4032000309312Bell et al., 2009A.H.BellF.Hadj-BouzianeJ.B.FrihaufR.B.TootellL.G.UngerleiderObject representations in the temporal cortex of monkeys and humans as revealed by functional magnetic resonance imagingJ. Neurophysiol.1012009688700Binder et al., 2009J.R.BinderR.H.DesaiW.W.GravesL.L.ConantWhere is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studiesCereb. Cortex19200927672796Birn et al., 2010R.M.BirnL.KenworthyL.CaseR.CaravellaT.B.JonesP.A.BandettiniA.MartinNeural systems supporting lexical search guided by letter and semantic category cues: a self-paced overt response fMRI study of verbal fluencyNeuroimage49201010991107Bookheimer, 2002S.BookheimerFunctional MRI of language: new approaches to understanding the cortical organization of semantic processingAnnu. Rev. Neurosci.252002151188Buonomano and Merzenich, 1998D.V.BuonomanoM.M.MerzenichCortical plasticity: from synapses to mapsAnn. Rev. Neurosci.211998149186Buxbaum et al., 2006L.J.BuxbaumK.M.KyleK.TangJ.A.DetreNeural substrates of knowledge of hand postures for object grasping and functional object use: evidence from fMRIBrain Res.11172006175185Canessa et al., 2008N.CanessaF.BorgoS.F.CappaD.PeraniA.FaliniG.BuccinoM.TettamantiT.ShalliceThe different neural correlates of action and functional knowledge in semantic memory: an FMRI studyCereb. Cortex182008740751Clarke et al., 2000S.ClarkeA.BellmannR.A.MeuliG.AssalA.J.SteckAuditory agnosia and auditory spatial deficits following left hemispheric lesions: evidence for distinct processing pathwaysNeuropsychologia382000797807Creutzfeldt et al., 1989O.CreutzfeldtG.OjemannE.LettichNeuronal activity in the human lateral temporal lobe. I. Responses to speechExp. Brain Res.771989451475Dale, 1999A.M.DaleOptimal experimental design for event-related fMRIHum. Brain Mapp.81999109114Daltrozzo and Schön, 2009J.DaltrozzoD.SchönConceptual processing in music as revealed by N400 effects on words and musical targetsJ. Cogn. Neurosci.21200918821892Damasio et al., 2004H.DamasioD.TranelT.GrabowskiR.AdolphsA.DamasioNeural systems behind word and concept retrievalCognition922004179229De Houwer et al., 2009J.De HouwerS.Teige-MocigembaA.SpruytA.MoorsImplicit measures: a normative analysis and reviewPsychol. Bull.1352009347368Elbert et al., 1995T.ElbertC.PantevC.WienbruchB.RockstrohE.TaubIncreased cortical representation of the fingers of the left hand in string playersScience2701995305307Fischer, 1950R.FischerStatistical Methods for Research Workers11 ed.1950Oliver & BoydLondonFuggetta et al., 2009G.FuggettaS.RizzoG.PobricM.LavidorV.WalshFunctional representation of living and nonliving domains across the cerebral hemispheres: a combined event-related potential/transcranial magnetic stimulation studyJ. Cogn. Neurosci.212009403414Gallese and Lakoff, 2005V.GalleseG.LakoffThe brain's concepts: the role of the sensory-motor system in conceptual knowledgeCognit. Neuropsychol.222005455479Grossman et al., 2004E.D.GrossmanR.BlakeC.Y.KimLearning to see biological motion: brain activity parallels behaviorJ. Cogn. Neurosci.16200416691679Gusnard et al., 2001aD.A.GusnardE.AkbudakG.L.ShulmanM.E.RaichleMedial prefrontal cortex and self-referential mental activity: relation to a default mode of brain functionProc. Natl. Acad. Sci. USA98200142594264Gusnard et al., 2001bD.A.GusnardM.E.RaichleM.E.RaichleSearching for a baseline: functional imaging and the resting human brainNat. Rev. Neurosci.22001685694Halpern et al., 2004A.R.HalpernR.J.ZatorreM.BouffardJ.A.JohnsonBehavioral and neural correlates of perceived and imagined musical timbreNeuropsychologia42200412811292Hänggi et al., 2009J.HänggiS.KoenekeL.BezzolaL.JänckeStructural neuroplasticity in the sensorimotor network of professional female ballet dancersHum. Brain Mapp.2009Epub ahead of print.Hauk et al., 2006O.HaukM.H.DavisM.FordF.PulvermullerW.D.Marslen-WilsonThe time course of visual word recognition as revealed by linear regression analysis of ERP dataNeuroimage30200613831400Hauk et al., 2008O.HaukM.H.DavisF.KherifF.PulvermullerImagery or meaning? Evidence for a semantic origin of category-specific brain activity in metabolic imagingEurop. J. Neurosci.27200818561866Hoenig and Scheef, 2009K.HoenigL.ScheefNeural correlates of semantic ambiguity processing during context verificationNeuroimage45200910091019Hoenig et al., 2008K.HoenigE.-J.SimV.BochevB.HerrnbergerM.KieferConceptual flexibility in the human brain: dynamic recruitment of semantic maps from visual, motor, and motion-related areasJ. Cogn. Neurosci.20200817991814Howard et al., 2000M.A.HowardI.O.VolkovR.MirskyP.C.GarellM.D.NohM.GrannerH.DamasioM.SteinschneiderR.A.RealeJ.E.HindJ.F.BruggeAuditory cortex on the human posterior superior temporal gyrusJ. Comp. Neurol.41620007992Hubbard, 2010T.L.HubbardAuditory imagery: empirical findingsPsychol. Bull.1362010302329Humphreys et al., 1988G.W.HumphreysM.J.RiddochP.T.QuinlanCascade processes in picture identificationCognit. Neuropsychol.5198867103Hurley et al., 2009R.S.HurleyK.A.PallerC.A.WienekeS.WeintraubC.K.ThompsonK.D.FedermeierM.M.MesulamElectrophysiology of object naming in primary progressive aphasiaJ. Neurosci.2920091576215769Hwang et al., 2009K.HwangE.D.PalmerS.BashoJ.R.ZadraR.A.MullerCategory-specific activations during word generation reflect experiential sensorimotor modalitiesNeuroimage482009717725Hyde et al., 2008K.L.HydeI.PeretzR.J.ZatorreEvidence for the role of the right auditory cortex in fine pitch resolutionNeuropsychologia462008632639James and Gauthier, 2003T.W.JamesI.GauthierAuditory and action semantic features activate sensory-specific perceptual brain regionsCurr. Biol.13200317921796Jolicoeur et al., 1984P.JolicoeurM.GluckS.KosslynPicture and names: making the connectionCognit. Psychol.161984243275Kellenbach et al., 2001M.L.KellenbachM.BrettK.PattersonLarge, colorful, or noisy? Attribute- and modality-specific activations during retrieval of perceptual attribute knowledgeCogn. Affect. Behav. Neurosci.12001207221Kellenbach et al., 2003M.L.KellenbachM.BrettK.PattersonActions speak louder than functions: the importance of manipulability and action in tool representationJ. Cogn. Neurosci.1520033046Kiefer, 2005M.KieferRepetition priming modulates category-related effects on event-related potentials: further evidence for multiple cortical semantic systemsJ. Cogn. Neurosci.172005199211Kiefer and Spitzer, 2001M.KieferM.SpitzerThe limits of a distributed account of conceptual knowledgeTrends Cogn. Sci.52001469471Kiefer et al., 2007M.KieferE.-J.SimS.LiebichO.HaukJ.W.TanakaExperience-dependent plasticity of conceptual representations in human sensory-motor areasJ. Cogn. Neurosci.192007525542Kiefer et al., 2008M.KieferE.-J.SimB.HerrnbergerJ.GrotheK.HoenigThe sound of concepts: four markers for a link between auditory and conceptual brain systemsJ. Neurosci.2820081222412230Kim, 2010H.KimDissociating the roles of the default-mode, dorsal, and ventral networks in episodic memory retrievalNeuroimage50201016481657Koelsch, 2005S.KoelschNeural substrates of processing syntax and semantics in musicCurr. Opin. Neurobiol.152005207212Koelsch and Siebel, 2005S.KoelschW.A.SiebelTowards a neural basis of music perceptionTrends Cogn. Sci.92005578584Koelsch et al., 2004S.KoelschE.KasperD.SammlerK.SchulzeT.GunterA.D.FriedericiMusic, language and meaning: brain signatures of semantic processingNat. Neurosci.72004302307Kosslyn, 1994S.M.KosslynImage and Brain: The Resolution of the Imagery Debate1994MIT PressCambridge, MAKotz et al., 2006S.A.KotzM.MeyerS.PaulmannLateralization of Emotional Prosody in the Brain: An Overview and Synopsis on the Impact of Study DesignS.AndersG.EndeM.JunghöferJ.KisslerD.WildgruberUnderstanding Emotions2006ElsevierAmsterdam285294Kouider et al., 2010S.KouiderV.de GardelleS.DehaeneE.DupouxC.PallierCerebral bases of subliminal speech primingNeuroimage492010922929Kraemer et al., 2005D.J.KraemerC.N.MacraeA.E.GreenW.M.KelleyMusical imagery: sound of silence activates auditory cortexNature4342005158Lappe et al., 2008C.LappeS.C.HerholzL.J.TrainorC.PantevCortical plasticity induced by short-term unimodal and multimodal musical trainingJ. Neurosci.28200896329639Lawrence et al., 2008E.J.LawrenceK.RubiaR.M.MurrayP.K.McGuireM.WalsheM.AllinV.GiampietroL.RifkinS.C.WilliamsC.NosartiThe neural basis of response inhibition and attention allocation as mediated by gestational ageHum. Brain Mapp.2008Lazar et al., 2002N.A.LazarB.LunaJ.A.SweeneyW.F.EddyCombining brains: a survey of methods for statistical pooling of informationNeuroimage162002538550Levelt et al., 1999W.J.LeveltA.RoelofsA.S.MeyerA theory of lexical access in speech productionBehav. Brain Sci.221999138discussion 38–75Lewis et al., 2004J.W.LewisF.L.WightmanJ.A.BrefczynskiR.E.PhinneyJ.R.BinderE.A.DeYoeHuman brain regions involved in recognizing environmental soundsCereb. Cortex14200410081021Liegeois-Chauvel et al., 1998C.Liegeois-ChauvelI.PeretzM.BabaiV.LaguittonP.ChauvelContribution of different cortical areas in the temporal lobes to music processingBrain121199818531867Lyons et al., 2010I.M.LyonsA.Mattarella-MickeM.CieslakH.C.NusbaumS.L.SmallS.L.BeilockThe role of personal experience in the neural processing of action-related languageBrain Lang.1122010214222Maeder et al., 2001P.P.MaederR.A.MeuliM.AdrianiA.BellmannE.FornariJ.P.ThiranA.PittetS.ClarkeDistinct pathways involved in sound recognition and localization: a human fMRI studyNeuroimage142001802816Mahon and Caramazza, 2009B.Z.MahonA.CaramazzaConcepts and categories: a cognitive neuropsychological perspectiveAnn. Rev. Psychol.6020092751Mahon et al., 2009B.Z.MahonS.AnzellottiJ.SchwarzbachM.ZampiniA.CaramazzaCategory-specific organization in the human brain does not require visual experienceNeuron632009397405Marshall et al., 1990J.MarshallC.PoundM.White-ThomsonT.PringThe use of picture/word matching tasks to assist word retrieval in aphasic patientsAphasiology41990167184Martin and Chao, 2001A.MartinL.L.ChaoSemantic memory and the brain: structure and processesCurr. Opin. Neurobiol.112001194201Martin et al., 1996A.MartinC.L.WiggsL.G.UngerleiderJ.V.HaxbyNeural correlates of category-specific knowledgeNature3791996649652Mashal et al., 2009N.MashalM.FaustT.HendlerM.Jung-BeemanAn fMRI study of processing novel metaphoric sentencesLaterality1420093054Mathalon et al., 2002D.H.MathalonW.O.FaustmanJ.M.FordN400 and automatic semantic processing abnormalities in patients with schizophreniaArch. Gen. Psychiatry592002641648Meyer, 1977A.MeyerIs there an anatomical localisation for musical faculties?M.CritchleyR.N.HensonMusic and the Brain: Studies in the Neurology of Music1977Heinemann MedicalLondon255281Moors and De Houwer, 2006A.MoorsJ.De HouwerAutomaticity: a theoretical and conceptual analysisPsychol. Bull.1322006297326Münte et al., 2002T.F.MünteE.AltenmüllerL.JänckeThe musician's brain as a model of neuroplasticityNat. Rev. Neurosci.32002473478Nielsen and Cohen, 2008J.B.NielsenL.G.CohenThe Olympic brain. Does corticospinal plasticity play a role in acquisition of skills required for high-performance sports?J. Physiol. Lond.58620086570Nieuwenhuys et al., 2008R.NieuwenhuysJ.VoogdC.van HujizenThe Human Central Nervous System3 ed.2008SpringerBerlinNoppeney et al., 2006U.NoppeneyC.J.PriceW.D.PennyK.J.FristonTwo distinct neural mechanisms for category-selective responsesCereb. Cortex162006437445Obleser and Kotz, 2010J.ObleserS.A.KotzExpectancy constraints in degraded speech modulate the language comprehension networkCereb. Cortex202010633640Ojemann et al., 1988G.A.OjemannO.CreutzfeldtE.LettichM.M.HaglundNeuronal activity in human lateral temporal cortex related to short-term verbal memory, naming and readingBrain111Pt 6198813831403Oldfield, 1971R.OldfieldThe assessment and analysis of handedness: the Edinburgh InventoryNeuropsychologia9197197113Pantev et al., 1998C.PantevR.OostenveldA.EngelienB.RossL.E.RobertsM.HokeIncreased auditory cortical representation in musiciansNature3921998811814Pantev et al., 2001C.PantevL.E.RobertsM.SchulzA.EngelienB.RossTimbre-specific enhancement of auditory cortical representations in musiciansNeuroReport122001169174Parsons, 2001L.M.ParsonsExploring the functional neuroanatomy of music performance, perception, and comprehensionAnn. NY Acad. Sci.9302001211231Peretz, 1990I.PeretzProcessing of local and global musical information by unilateral brain-damaged patientsBrain113199011851205Pietrini et al., 2004P.PietriniM.L.FureyE.RicciardiM.I.GobbiniW.H.WuL.CohenM.GuazzelliJ.V.HaxbyBeyond sensory images: object-based representation in the human ventral pathwayProc. Natl. Acad. Sci. USA101200456585663Platel et al., 1997H.PlatelC.PriceJ.C.BaronR.WiseJ.LambertR.S.FrackowiakB.LechevalierF.EustacheThe structural components of music perception. A functional anatomical studyBrain1201997229243Polley et al., 2006D.B.PolleyE.E.SteinbergM.M.MerzenichPerceptual learning directs auditory cortical map reorganization through top-down influencesJ. Neurosci.26200649704982Posner and Snyder, 1975M.I.PosnerC.R.R.SnyderAttention and cognitive controlR.L.SolsoInformation Processing and Cognition: The Loyota Symposium1975Lawrence Erlbaum AssociatesHillsdale5585Price, 2000C.J.PriceThe anatomy of language: contributions from functional neuroimagingJ. Anat.197Pt 32000335359Price, 2010C.J.PriceThe anatomy of language: a review of 100 fMRI studies published in 2009Ann. NY Acad. Sci.119120106288Pulvermüller, 2005F.PulvermüllerBrain mechanisms linking language and actionNat. Rev. Neurosci.62005576582Raichle et al., 2001M.E.RaichleA.M.MacLeodA.Z.SnyderW.J.PowersD.A.GusnardG.L.ShulmanA default mode of brain functionProc. Natl. Acad. Sci. USA982001676682Rogers et al., 2004T.RogersM.A.Lambon RalphP.GarrardS.BozeatJ.L.McClellandJ.R.HodgesK.PattersonThe structure and deterioration of semantic memory: a neuropsychological and computational investigationPsychol. Rev.1112004205235Rorden and Brett, 2000C.RordenM.BrettStereotaxic display of brain lesionsBehav. Neurol.122000191200Schacter and Tulving, 1994D.L.SchacterE.TulvingWhat are the memory systems of 1994?D.L.SchacterE.TulvingMemory Systems 19941994MIT PressCambridge, MA138Schirmer and Kotz, 2006A.SchirmerS.A.KotzBeyond the right hemisphere: brain mechanisms mediating vocal emotional processingTrends Cogn. Sci.1020062430Schlaug et al., 1995G.SchlaugL.JänckeY.HuangJ.F.StaigerH.SteinmetzIncreased corpus callosum size in musiciansNeuropsychologia33199510471055Schneider et al., 2005P.SchneiderV.SlumingN.RobertsM.SchergR.GoebelH.J.SpechtH.G.DoschS.BleeckC.StippichA.RuppStructural and functional asymmetry of lateral Heschl's gyrus reflects pitch perception preferenceNat. Neurosci.8200512411247Schurmann et al., 2002M.SchurmannT.RaijN.FujikiR.HariMind's ear in a musician: where and when in the brainNeuroimage162002434440Sharp et al., 2010D.J.SharpM.AwadJ.E.WarrenR.J.WiseG.ViglioccoS.K.ScottThe neural response to changing semantic and perceptual complexity during language processingHum. Brain Mapp.312010365377Simmons and Barsalou, 2003W.SimmonsL.W.BarsalouThe similarity-in-topography principle: reconciling theories of conceptual deficitsCognit. Neuropsychol.202003451486Sirigu et al., 1995A.SiriguL.CohenJ.R.DuhamelB.PillonB.DuboisY.AgidA selective impairment of hand posture for object utilization in apraxiaCortex3119954155Sirigu et al., 1996A.SiriguJ.R.DuhamelL.CohenB.PillonB.DuboisY.AgidThe mental representation of hand movements after parietal cortex damageScience273199615641568Solomon and Barsalou, 2004K.O.SolomonL.W.BarsalouPerceptual simulation in property verificationMem. Cognit.322004244259Specht and Reul, 2003K.SpechtJ.ReulFunctional segregation of the temporal lobes into highly differentiated subsystems for auditory perception: an auditory rapid event-related fMRI-taskNeuroimage20200319441954Steinbeis and Koelsch, 2008N.SteinbeisS.KoelschComparing the processing of music and language meaning using EEG and FMRI provides evidence for similar and distinct neural representationsPLoS ONE32008e2226Tanaka and Taylor, 1991J.W.TanakaM.TaylorObject categories and expertise: is the basic level in the eye of the beholder?Cognit. Psychol.231991457482Tanaka et al., 1999J.W.TanakaP.LuuM.WeisbrodM.KieferTracking the time course of object categorization using event-related potentialsNeuroReport101999829835Tramo, 2001M.J.TramoBiology and music. Music of the hemispheresScience29120015456Tramo and Bharucha, 1991M.J.TramoJ.J.BharuchaMusical priming by the right hemisphere post-callosotomyNeuropsychologia291991313325Tremblay and Gracco, 2010P.TremblayV.L.GraccoOn the selection of words and oral motor responses: evidence of a response-independent fronto-parietal networkCortex4620101528Tulving, 1972E.TulvingEpisodic and semantic memoryE.TulvingW.DonaldsonOrganization of Memory1972Academic PressNew York381403Tyler and Moss, 2001L.K.TylerH.E.MossTowards a distributed account of conceptual knowledgeTrends Cogn. Sci.52001244252Vingerhoets, 2008G.VingerhoetsKnowing about tools: neural correlates of tool familiarity and experienceNeuroimage40200813801391Warrington and McCarthy, 1987E.K.WarringtonR.McCarthyCategories of knowledgeBrain110198712731296Weisberg et al., 2007J.WeisbergM.van TurennoutA.MartinA neural system for learning about object functionCereb. Cortex172007513521Wheeler et al., 2000M.E.WheelerS.E.PetersenR.L.BucknerMemory's echo: vivid remembering reactivates sensory-specific cortexProc. Natl. Acad. Sci. USA9720001112511129Whitney et al., 2009C.WhitneyW.HuberJ.KlannS.WeisS.KrachT.KircherNeural correlates of narrative shifts during auditory story comprehensionNeuroimage472009360366Willems et al., 2010R.M.WillemsI.ToniP.HagoortD.CasasantoNeural dissociations between action verb understanding and motor imageryJ. Cogn. Neurosci.22201023872400Woolsey, 1982C.N.WoolseyCortical Sensory Organization. Multiple Auditory Areas1982Humana pressClifton, NJWu et al., 2006J.WuX.MaiC.C.ChanY.ZhengY.LuoEvent-related potentials during mental imagery of animal soundsPsychophysiol.432006592597Zatorre and Halpern, 2005R.J.ZatorreA.R.HalpernMental concerts: musical imagery and auditory cortexNeuron472005912Zatorre et al., 1992R.J.ZatorreA.C.EvansE.MeyerA.GjeddeLateralization of phonetic and pitch discrimination in speech processingScience2561992846849Zatorre et al., 1996R.J.ZatorreA.R.HalpernD.W.PerryE.MeyerA.C.EvansHearing in the mind's ear: a PET investigation of musical imagery and perceptionJ. Cogn. Neurosci.819962946Zhou and Merzenich, 2007X.ZhouM.M.MerzenichIntensive training in adults refines A1 representations degraded in an early postnatal critical periodProc. Natl. Acad. Sci. USA10420071593515940"],"assetTypes":["IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","IMAGE","DOCUMENT","IMAGE","TABULAR_DATA","TABULAR_DATA"],"snippets":["Sensorimotor conceptual enrichment. Increased relevance ratings of acoustic, visual, and motor features for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> in musicians (N=20) compared to non-musicians (N=20), demonstrating the conceptual enrichment for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> due to the intensive sensorimotor experiences of musicians with these objects. p&lt;0.001 for each of the post-hoc comparisons between musicians and non-musicians; small vertical bars indicate the standard error of means (s.e.m.).\n","Perceptual processing of real sounds and overlap between auditory perceptual and conceptual brain activation. A, Perceptual task: Activation during listening to real sounds, pmusical \u003cstrong>instruments\u003c/strong> compared to control objects in musicians (N=20), but not in non-musicians (N=20; pacoustic noise) and the conceptual group-by-object interaction (group: musicians&gt;non-musicians, object: \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> (MI)&gt;control objects (CO)), respectively. Shown are contiguous slices centered on the peak coordinates (68–42 0) obtained from the interaction analysis of the conceptual task. P=posterior, A=anterior, MI=\u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>, CO=control objects.\n","Norming results of the stimulus material. Shown are the average values of the behavioral ratings for the relevance of acoustic (Ac), visual (Vis), and motor (Mot) features as well as of emotional valence (Emot), familiarity (Fam) and visual complexity (Vcom) of the pictures for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> and control objects. Data were obtained from an independent prior norming study. \u003cstrong>Musical\u003c/strong> \u003cstrong>instruments\u003c/strong> and control objects differed only with respect to acoustic concept features. ***p&lt;0.001; small vertical bars indicate the standard error of means (s.e.m.).\n","Professional musicians constitute a model par excellence for understanding experience-dependent plasticity in the human brain, particularly in the auditory domain. Their intensive sensorimotor experience with \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> has been shown to entail plastic brain alterations in cortical perceptual and motor maps. It remains an important question whether this neuroplasticity might extend beyond basic perceptual and motor functions and even shape higher-level conceptualizations by which we conceive our physical and social world. Here we show using functional magnetic resonance imaging (fMRI) that conceptual processing of visually presented \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> activates auditory association cortex encompassing right posterior superior temporal gyrus, as well as adjacent areas in the superior temporal sulcus and the upper part of middle temporal gyrus (pSTG/MTG) only in musicians, but not in \u003cstrong>musical\u003c/strong> laypersons. These areas in and adjacent to auditory association cortex were not only recruited by conceptual processing of \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> during visual object recognition, but also by auditory perception of real sounds. Hence, the unique intensive experience of musicians with \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> establishes a link between auditory perceptual and conceptual brain systems. Experience-driven neuroplasticity in musicians is thus not confined to alterations of perceptual and motor maps, but even leads to the establishment of higher-level semantic representations for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> in and adjacent to auditory association cortex. These findings highlight the eminent importance of sensory and motor experience for acquiring rich concepts.","Functional interaction effects between Group (musicians vs. non-musicians) and Object (\u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> vs. control objects). A, Multi-slice view of increased functional activation to \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> compared to control objects for musicians (N=20) compared with non-musicians (N=20), pmusical \u003cstrong>instruments\u003c/strong> and control objects to brain activation at the peak voxel of the respective cluster for musicians and non-musicians.\n","Functional brain activation pertaining to acoustic conceptual features of \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong>. A, Brain activation of the conceptual group-by-object contrast: Increased activation to \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> compared to control objects for musicians (N=20) compared with non-musicians (N=20) in right pSTG/MTG, pmusical \u003cstrong>instruments\u003c/strong> and control objects to brain activation at the peak voxel of the pSTG/MTG cluster for musicians and non-musicians. The bar chart shows that the interaction effect is due to a differentially larger activation increase for \u003cstrong>musical\u003c/strong> \u003cstrong>instruments\u003c/strong> compared with control objects in musicians than in non-musicians. P=posterior, A=anterior, L=left, R=right.\n"],"rsindex":6},{"id":"051054054053053053049058103114111046111100111110101122058105097111:ZENODO","externalId":"oai:zenodo.org:1555663","containerTitle":"The \u003cstrong>Music\u003c/strong> and \u003cstrong>Musical\u003c/strong> \u003cstrong>Instruments\u003c/strong> of the Bible","source":"ZENODO","containerType":"article","lastImported":"2018-11-27T00:00:00Z","externalContainerType":"info:eu-repo/semantics/article,publication-article,","containerDescription":"n/a","doi":"doi:10.2307/906927","publicationDate":"1914-06-01","containerDataTypes":["DOCUMENT"],"dateAvailable":"2018-11-26","externalDateModified":"2018-11-26","repoType":"NON_ARTICLE_BASED_REPOSITORY","accessRights":"info:eu-repo/semantics/openAccess","containerURI":"https://zenodo.org/record/1555663","subjectAreas":["Computer Science"],"authors":[{"name":"Schlesinger, Kathleen"},{"name":"Stainer, John"}],"assetTypes":["DOCUMENT"],"rsindex":7},{"id":"055052049056055049049058103114111046111100111110101122058105097111:ZENODO","externalId":"oai:zenodo.org:1178147","containerTitle":"MelodyMorph: A Reconfigurable \u003cstrong>Musical\u003c/strong> \u003cstrong>Instrument\u003c/strong>","source":"ZENODO","containerType":"article","lastImported":"2018-07-27T00:00:00Z","externalContainerType":"info:eu-repo/semantics/conferencePaper,publication-conferencepaper,","containerDescription":"I present MelodyMorph, a reconfigurable \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> designed with a focus on melodic improvisation. It is designed for a touch-screen interface, and allows the user to create \"bells\" which can be tapped to play a note, and dragged around on a pannable and zoomable canvas. Colors, textures and shapes of the bells represent pitch and timbre properties. \"Recorder bells\" can store and play back performances. Users can construct \u003cstrong>instruments\u003c/strong> that are modifiable as they play, and build up complex melodies hierarchically from simple parts.","doi":"doi:10.5281/zenodo.1178147","publicationDate":"2011-06-01","containerDataTypes":["DOCUMENT"],"dateAvailable":"2018-06-28","externalDateModified":"2018-06-28","repoType":"NON_ARTICLE_BASED_REPOSITORY","accessRights":"info:eu-repo/semantics/openAccess","containerURI":"https://zenodo.org/record/1178147","authors":[{"name":"Rosenbaum, Eric"}],"relatedResources":["doi:10.5281/zenodo.1178146"],"assetTypes":["DOCUMENT"],"snippets":["I present MelodyMorph, a reconfigurable \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> designed with a focus on melodic improvisation. It is designed for a touch-screen interface, and allows the user to create \"bells\" which can be tapped to play a note, and dragged around on a pannable and zoomable canvas. Colors, textures and shapes of the bells represent pitch and timbre properties. \"Recorder bells\" can store and play back performances. Users can construct \u003cstrong>instruments\u003c/strong> that are modifiable as they play, and build up complex melodies hierarchically from simple parts."],"rsindex":8},{"institution":["Music"],"id":"053054050:UNIVERSITY_OF_VIRGINIA","externalId":"265","containerTitle":"Bellona_Jon_2018_PhD_Distance-X_software","source":"UNIVERSITY_OF_VIRGINIA","containerType":"article","lastImported":"2018-10-11T00:00:00Z","containerDescription":"Software of Distance-X, a custom built alternate controller digital \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong>. All software related to Jon Bellona's 2018 PhD Dissertation entitled, Physical Composition: The \u003cstrong>Musicality\u003c/strong> of Body Movement on Digital \u003cstrong>Musical\u003c/strong> \u003cstrong>Instruments\u003c/strong>.","doi":"doi:10.18130/V3/DQQZOG","publicationDate":"2018-04-27","containerDataTypes":["IMAGE","FILE_SET"],"dateCreated":"2018-04-28","dateAvailable":"2018-04-28","externalDateModified":"2018-04-28","repoType":"NON_ARTICLE_BASED_REPOSITORY","version":"1.2","accessRights":"CC0","contact":"[\"jpb5zh@Virginia.EDU\"]","howToCite":"Bellona, Jon, 2018, \"Bellona_Jon_2018_PhD_Distance-X_software\", https://doi.org/10.18130/V3/DQQZOG, University of Virginia Dataverse, V1","containerURI":"https://doi.org/10.18130/V3/DQQZOG","subjectAreas":["Arts and Humanities (Ex: English, History, Foreign, Language)"],"authors":[{"name":"Bellona, Jon"}],"assetTypes":["IMAGE","FILE_SET"],"snippets":["Software of Distance-X, a custom built alternate controller digital \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong>. All software related to Jon Bellona's 2018 PhD Dissertation entitled, Physical Composition: The \u003cstrong>Musicality\u003c/strong> of Body Movement on Digital \u003cstrong>Musical\u003c/strong> \u003cstrong>Instruments\u003c/strong>.","Software for Distance-X, a custom built alternate controller digital \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong>. All software related to Jon Bellona's 2018 PhD Dissertation entitled, Physical Composition: The \u003cstrong>Musicality\u003c/strong> of Body Movement on Digital \u003cstrong>Musical\u003c/strong> \u003cstrong>Instruments\u003c/strong>.","\u003cstrong>Music\u003c/strong>"],"rsindex":9},{"id":"049050051048056049049058103114111046111100111110101122058105097111:ZENODO","externalId":"oai:zenodo.org:1180321","containerTitle":"MelodyMorph: A Reconfigurable \u003cstrong>Musical\u003c/strong> \u003cstrong>Instrument\u003c/strong>","source":"ZENODO","containerType":"article","lastImported":"2018-07-26T00:00:00Z","externalContainerType":"info:eu-repo/semantics/conferencePaper,publication-conferencepaper,","containerDescription":"I present MelodyMorph, a reconfigurable \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> designed with a focus on melodic improvisation. It is designed for a touch-screen interface, and allows the user to create \"bells\" which can be tapped to play a note, and dragged around on a pannable and zoomable canvas. Colors, textures and shapes of the bells represent pitch and timbre properties. \"Recorder bells\" can store and play back performances. Users can construct \u003cstrong>instruments\u003c/strong> that are modifiable as they play, and build up complex melodies hierarchically from simple parts.","doi":"doi:10.5281/zenodo.1180321","publicationDate":"2011-06-01","containerDataTypes":["OTHER"],"dateAvailable":"2018-02-20","externalDateModified":"2018-02-20","repoType":"NON_ARTICLE_BASED_REPOSITORY","accessRights":"info:eu-repo/semantics/openAccess","containerURI":"https://zenodo.org/record/1180321","authors":[{"name":"Rosenbaum, Eric"}],"relatedResources":["doi:10.5281/zenodo.1180320"],"assetTypes":[],"snippets":["I present MelodyMorph, a reconfigurable \u003cstrong>musical\u003c/strong> \u003cstrong>instrument\u003c/strong> designed with a focus on melodic improvisation. It is designed for a touch-screen interface, and allows the user to create \"bells\" which can be tapped to play a note, and dragged around on a pannable and zoomable canvas. Colors, textures and shapes of the bells represent pitch and timbre properties. \"Recorder bells\" can store and play back performances. Users can construct \u003cstrong>instruments\u003c/strong> that are modifiable as they play, and build up complex melodies hierarchically from simple parts."],"rsindex":10}],"count":3889,"query":"musical instruments","facets":{"range":{"publicationDate":{"min":"1561-12-22","max":"2020-01-23"}},"list":{"repositoryType":{"ARTICLE_BASED_REPOSITORY":686,"NON_ARTICLE_BASED_REPOSITORY":3203},"source":{"bl.leeds":6,"cisti.ubc":115,"crui.unibo":6,"nrct.db1":7,"figshare.ars":113,"rutgers.lib":27,"ARXIV":93,"figshare.sage":18,"tib.kmo":47,"viva.uva-libra":14,"sage.dplanet":361,"bl.gold":6,"ands.centre-3":73,"crui.unile":5,"cmu.kilthub":20,"heallink.ntua":11,"cisti.ucalgary":11,"umd.lib":69,"ZENODO":1189,"tib.fuub":16,"bl.dri":7,"uky.lib":22,"usc.dl":271,"APOLLO":78,"msu.libraries":21,"ands.centre13":28,"cul.columbia":40,"SMITHSONIANDIGITALREPOSITORY":5,"cos.osf":8,"psnc.pan-cc":112,"crui.unipv":14,"cyberl.cyberdoi":80,"DSPACEUNIVERSITYOFWASHINGTON":22,"mla.hc":44,"SCIENCE_DIRECT":462,"tib.tub":26,"subgoe.vzg":54,"ands.centre66":5,"bl.oxdb":16,"gdcc.odum-library":20,"rstat.library":7,"cisti.uottawa":19,"ICPSR":16,"tib.univie":36,"NEURO_ELECTRO":7,"bl.salford":11,"DATASPACE":24,"bl.rcm":5,"tib.tudo":7,"gesis.icpsr":75},"type":{"COLLECTION":126,"PHYSICAL_OBJECT":5,"VIDEO":94,"DATASET":426,"TEXT":8,"AUDIO":64,"OTHER":1134,"SLIDES":2,"SOFTWARE_CODE":1,"IMAGE":544,"TABULAR_DATA":419,"DOCUMENT":1427,"FILE_SET":68,"WORKFLOW":3}}},"boostedDataResultsCount":3},"datasearchResultAssets":{"isFetchingAssets":false,"isError":false},"typeaheadResults":{"isFetching":false,"suggestions":[],"count":0,"fetchCount":0,"query":""},"projects":{"associations":[],"associationId":null,"datasets":[],"dataSources":[],"dragStatus":false,"userId":null,"kloudlessConfig":[],"kloudlessState":[],"kloudlessStorages":[],"projectId":"","title":"","description":"","selectedFolders":[],"selectFoldersData":{},"sharedFolders":{},"showSelectFoldersModal":false,"storageId":null,"members":[],"message":null},"params":{"query":"musical instruments","pageSize":10,"page":0,"facets":{}}},"routeConfig":[{"component":"PublicDatasetsSearchContainer","mountPoint":"results"}],"environment":"live"}
				</script>
				<link rel="stylesheet"
					href="https://static.mendeley.com/weblet-data/build/2000490/css/vendor/leaflet.css">
				<script
					src="https://static.mendeley.com/weblet-data/build/2000490/js/vendor.bundle.dcf29004d90f443a8da2.js">
				</script>
				<script
					src="https://static.mendeley.com/weblet-data/build/2000490/js/app.bundle.e15e8106da26e899db82.js">
				</script>

			</div>
		</main>



	</div>



	<footer class="footer">
		<div class="footer-feedback">
			<div class="width-container">
				<span class="footer-feedback-icon"></span>
				<a class="footer-feedback-header-link"
					href="https://service.elsevier.com/app/contact/supporthub/mendeley/">We care about your feedback</a>
				Help us to improve Mendeley Data by telling us what we can do better.
				<a href="https://www.techvalidate.com/registration/a3152100f6"
					class="btn btn-tight btn-send-feedback">Send feedback</a>
			</div>
		</div>
		<div class="width-container">
			<div class="footer-row bottom-footer">
				<div class="footer-column d-1-1 m-1-1 s-1-1 xs-1-1 footer-social-links">
					<span class="related-links">
          <a class="footer-related-link" href="/mission">Mission</a>
          <a class="footer-related-link" href="/archive-process">Archive Policy</a>
          <a class="footer-related-link" href="/file-formats">Suggested file formats</a>
        </span>
					<a href="https://www.facebook.com/mendeley/" title="Facebook"
						target="_blank"><img src="//static.mendeley.com/weblet-feed/build/868/images/facebook.svg" alt="Facebook"></a>
						<a href="https://twitter.com/mendeley_com" title="Twitter"
							target="_blank"><img src="//static.mendeley.com/weblet-feed/build/868/images/twitter.svg" alt="Twitter"></a>
							<a href="https://www.linkedin.com/company/mendeley" title="LinkedIn"
								target="_blank"><img src="//static.mendeley.com/weblet-feed/build/868/images/linkedin.svg" alt="LinkedIn"></a>
				</div>
			</div>
			<hr class="footer-hr">
			<div class="footer-row">
				<div class="footer-column d-1-4 m-1-4 s-1-1 xs-1-1 elsevier-logo">
					<a href="https://www.elsevier.com/" title="Elsevier"
						target="_blank"><img src="//static.mendeley.com/weblet-feed/build/868/images/elsevier.svg" alt="Elsevier"></a>
				</div>
				<div class="footer-column d-2-4 m-3-4 s-1-1 xs-1-1 footer-copyright">
					<ul class="footer-link-list">
						<li><a href="//www.mendeley.com/terms/copyright/" title="Copyright">Copyright</a></li>
						<li><a href="/terms/" title="Terms of Use">Terms of Use</a></li>
						<li><a href="https://www.elsevier.com/legal/privacy-policy" title="Privacy policy">Privacy
								Policy</a></li>
					</ul>
					<p>Copyright &copy; 2019 Mendeley Ltd. All rights reserved.
						<span class="m-block l-block">Cookies are set by this site. To decline them or learn more, visit our <a href="//www.mendeley.com/terms/cookie-policy/" title="cookies">cookies</a> page.</span>
					</p>
				</div>
				<div class="footer-column d-1-4 m-1-1 s-1-1 xs-1-1 relx-logo">
					<a href="http://www.relx.com/" title="RELX GroupTM"
						target="_blank"><img src="https://static.mendeley.com/weblet-data/build/2000490/images/relxlogo.jpg" alt="RELX GroupTM"></a>
				</div>
			</div>
		</div>
	</footer>

	<div data-component="overlay" class="overlay">
		<div class="overlay-modal"></div>

	</div>
	<div class="popover-panel"></div>
	<div data-component="viewer"></div>

	<script type="application/ld+json">
		{
  "@context" : "http://schema.org",
  "@type" : "WebSite",
  "name" : "Mendeley Data",
  "url" : "https://data.mendeley.com"
}
	</script>



	<script src="https://static.mendeley.com/weblet-data/build/2000490/js/lib/requirejs/require.min.js"></script>

	<script>
		(function() {
  window.webletDataConfig = {
    tracking: {"siteCatalyst":{"pageTypes":{"homepage":"np-hp","datasets":"sp-st","dataset":"cp-ca","register":"ap-ur","terms":"np-hp","faq":"np-hp","library":"np-ld","create":"cp-ca","preview":"cp-ca","default":"cp-ca"},"enabled":"true","script":"///assets.adobedtm.com/376c5346e33126fdb6b2dbac81e307cbacfd7935/satelliteLib-4a7497b2b1d1900fe42ef2c13e32daeedf9c1642.js","pageData":{"page":{"businessUnit":"els:rp:st","language":"en","loadTimestamp":"","name":"data","productName":"md","environment":"prod","noTracking":"false","type":"xxx"},"visitor":{"userId":"","accessType":"","ipAddress":""}}},"optimizely":{"enabled":"true","script":"https://cdn.optimizely.com/js/238413261.js"},"newRelic":{"enabled":true,"script":"&lt;!-- NREUM: (1) --&gt;"},"ua":"UA-3874710-27"},
    hotjarId: '246416',
    staticPath: 'https://static.mendeley.com/weblet-data/build/2000490'  }
  if (
    document.addEventListener &&
    document.querySelector &&
    window.localStorage &&
    window.getSelection &&
    'draggable' in document.body /* has drag and drop support? */
  ) {
    document.documentElement.className += ' js';
    require(['https://static.mendeley.com/weblet-data/build/2000490/js/main.min.js']);
  } else {
    require(['https://static.mendeley.com/weblet-data/build/2000490/js/simple.min.js']);
  }
})();
	</script>
	<script type="text/javascript">
		window.pageData = {"page":{"businessUnit":"els:rp:st","language":"en","loadTimestamp":1579880374201,"name":"data:datasets:browse","productName":"md","environment":"prod","noTracking":"false","type":"sp-st","loadTime":"361"},"visitor":{"userId":"md:guest","accessType":"md:guest","ipAddress":"191.83.175.78"}}; 
	</script>
	<script type="text/javascript">
		if(window.pageDataTracker) {
  pageDataTracker.trackPageLoad();
}
	</script>
</body>

</html>